# ğŸš€ Quick Start Guide

## âš¡ DÃ©marrage en 3 minutes

### 1ï¸âƒ£ Installation (30 secondes)

```bash
cd /home/y-aoub/my_projects/leboncoin_scraper
pip install -r requirements.txt
```

### 2ï¸âƒ£ Test avec l'interface (1 minute)

```bash
streamlit run ui.py
```

Une interface web s'ouvre automatiquement :
1. Choisissez une catÃ©gorie (ex: Immobilier)
2. SÃ©lectionnez une localisation (ex: Paris)
3. Cliquez sur "â–¶ï¸ Lancer le scraping"
4. Voyez les rÃ©sultats en temps rÃ©el !

### 3ï¸âƒ£ Ou en ligne de commande (1 minute)

```bash
# Utiliser une configuration d'exemple
cat config_examples.json | python -c "import sys, json; print(json.dumps(json.load(sys.stdin)['immobilier_paris']['config']))" > apify_input.json

# Lancer le scraper
python main.py

# Voir les rÃ©sultats
cat scraper_results.json
```

## ğŸ“– Fichiers importants

| Fichier | Description | Quand l'utiliser |
|---------|-------------|------------------|
| `ui.py` | Interface Streamlit | âœ… Pour tester et configurer |
| `main.py` | Script principal | âœ… Pour scraping production |
| `config_examples.json` | Configs prÃªtes | âœ… Pour dÃ©marrer rapidement |
| `test_scraper.py` | Tests automatiques | âœ… Pour valider l'installation |
| `README.md` | Doc complÃ¨te | ğŸ“š Pour tout comprendre |
| `USAGE.md` | Guide dÃ©taillÃ© | ğŸ“š Pour configuration avancÃ©e |

## ğŸ¯ Cas d'usage rapides

### Scraper l'immobilier Ã  Paris

```bash
streamlit run ui.py
# Dans l'interface:
# 1. CatÃ©gorie: "IMMOBILIER_VENTES_IMMOBILIERES"
# 2. Localisation: "DÃ©partement" â†’ "75"
# 3. Prix: 300000 - 800000
# 4. Cliquer "Lancer"
```

### Scraper des voitures en Ãle-de-France

```bash
# Copier la config exemple
echo '{
  "category": "VEHICULES_VOITURES",
  "location_type": "region",
  "locations": [{"name": "ILE_DE_FRANCE"}],
  "price_min": 5000,
  "price_max": 20000,
  "max_pages": 5
}' > apify_input.json

# Lancer
python main.py
```

### Scraper toutes les catÃ©gories dans une ville

```bash
echo '{
  "category": "TOUTES_CATEGORIES",
  "location_type": "city",
  "locations": [{
    "name": "Lyon",
    "lat": 45.764043,
    "lng": 4.835659,
    "radius": 15000
  }],
  "max_pages": 3
}' > apify_input.json

python main.py
```

## ğŸ§ª VÃ©rifier que tout fonctionne

```bash
python test_scraper.py
```

Tous les tests doivent passer âœ…

## ğŸ“Š Formats de sortie

### Mode UI (Streamlit)
- Visualisation en direct
- Export JSON/CSV via boutons
- Statistiques en temps rÃ©el

### Mode CLI
- `scraper_results.json` : RÃ©sultats complets avec stats
- `apify_output.json` : Toutes les annonces en tableau

## ğŸ”¥ Configurations prÃªtes Ã  l'emploi

Utilisez `config_examples.json` :

```bash
# Liste des configs disponibles
cat config_examples.json | python -c "import sys, json; [print(f'- {k}: {v[\"description\"]}') for k,v in json.load(sys.stdin).items()]"
```

Configs disponibles :
- `immobilier_paris` : Appartements Ã  Paris
- `voitures_ile_de_france` : Voitures en IdF
- `emploi_informatique` : Jobs IT
- `electronique_france` : Ã‰lectronique nationale
- `immobilier_complet` : Scraping immobilier DPE complet
- `tous_categories_region` : Multi-catÃ©gories

Pour utiliser une config :

```bash
# Extraire la config
cat config_examples.json | python -c "import sys, json; print(json.dumps(json.load(sys.stdin)['immobilier_paris']['config']))" > apify_input.json

# Lancer
python main.py
```

## ğŸ¨ Interface Streamlit - Guide visuel

### Zone latÃ©rale (Configuration)
1. **CatÃ©gorie** : Dropdown avec toutes les catÃ©gories
2. **Recherche** : Mots-clÃ©s optionnels
3. **Localisation** : Type (Ville/DÃ©partement/RÃ©gion) + sÃ©lection
4. **Filtres** : Prix, tri, type d'annonce
5. **Filtres avancÃ©s** : JSON personnalisÃ© selon catÃ©gorie
6. **Pagination** : Pages max, dÃ©lais
7. **Ã‚ge** : Filtrage par date
8. **Proxy** : Configuration optionnelle
9. **Format** : DÃ©taillÃ© ou compact

### Zone principale
- **Configuration actuelle** : PrÃ©visualisation JSON
- **Export** : Bouton pour sauvegarder la config
- **Actions** : Lancer/ArrÃªter
- **Statistiques** : MÃ©triques en temps rÃ©el
- **RÃ©sultats** : Onglets AperÃ§u/Export/DÃ©tails

## ğŸ’¡ Astuces pro

### 1. Test rapide avant production
```bash
# Dans apify_input.json, mettre:
"max_pages": 1,
"limit_per_page": 5
# â†’ Scrape 5 annonces pour tester
```

### 2. Export de config depuis UI
1. Configurer dans Streamlit
2. Cliquer "ğŸ’¾ Exporter configuration"
3. RÃ©cupÃ©rer `apify_input.json`
4. Utiliser en CLI : `python main.py`

### 3. Scraping par lots
```bash
# CrÃ©er plusieurs configs
echo '{"category": "VEHICULES_VOITURES", ...}' > config_voitures.json
echo '{"category": "IMMOBILIER", ...}' > config_immo.json

# Scraper chacune
for f in config_*.json; do
  cp "$f" apify_input.json
  python main.py
done
```

### 4. Mode debug
Dans `apify_input.json` :
```json
{
  "verbose": true,
  "max_pages": 1
}
```

## ğŸ› ProblÃ¨mes courants

### Erreur "Module not found"
```bash
pip install -r requirements.txt --upgrade
```

### Erreur 403 (Datadome)
Ajouter un proxy dans la config :
```json
{
  "proxy_host": "your-proxy.com",
  "proxy_port": 8080
}
```

### Pas de rÃ©sultats
VÃ©rifier que les filtres ne sont pas trop restrictifs :
- Retirer `max_age_days`
- Augmenter la plage de prix
- Essayer sans filtres avancÃ©s

### UI Streamlit ne dÃ©marre pas
```bash
# VÃ©rifier l'installation
pip install streamlit --upgrade

# VÃ©rifier le port
streamlit run ui.py --server.port 8502
```

## ğŸš€ DÃ©ployer sur Apify

### MÃ©thode 1 : Apify CLI
```bash
# Installer CLI
npm install -g apify-cli

# Login
apify login

# DÃ©ployer
apify push
```

### MÃ©thode 2 : GitHub
1. Push le code sur GitHub
2. Connecter GitHub Ã  Apify
3. Deploy automatique Ã  chaque push

### Fichiers nÃ©cessaires pour Apify
âœ… `main.py`
âœ… `requirements.txt`
âœ… `Dockerfile`
âœ… `.actor/actor.json`
âœ… `.actor/input_schema.json`

Tous sont dÃ©jÃ  prÃªts ! ğŸ‰

## ğŸ“ Besoin d'aide ?

1. **Documentation** : `README.md` et `USAGE.md`
2. **Tests** : `python test_scraper.py`
3. **Exemples** : `config_examples.json`
4. **Fichiers** : `FILES_OVERVIEW.md`

## âœ¨ C'est parti !

```bash
# La commande magique pour dÃ©marrer
streamlit run ui.py
```

Bon scraping ! ğŸ‰

